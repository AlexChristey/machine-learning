{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import hstack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reading csv files\n",
    "df =  pd.read_csv('adult.data', sep=\",\", header=None, skipinitialspace=True)\n",
    "df2 = pd.read_csv('adult.test', sep=\",\", header=None, skipinitialspace=True)\n",
    "\n",
    "# Join the data and test files together\n",
    "df = pd.concat([df, df2])\n",
    "\n",
    "# Shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Replace all of ? with None\n",
    "df = df.replace(['?'], [None])\n",
    "# Drop all rows with None in them\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# Check no None values remain\n",
    "df.isnull().sum()\n",
    "\n",
    "#Adding column headers to our data \n",
    "df.columns = [\"Age\", \"Workclass\", \"Fnlwgt\", \"Education\", \"Education-num\", \"Marital-status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\", \"Native-country\", \"Income\"]\n",
    "# Workclass, Fnlwgt, Race and Native-country are not worth using.\n",
    "# Education = Education num, so drop Education\n",
    "df = df.drop(columns=['Workclass', 'Race', 'Fnlwgt', 'Native-country', 'Education'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>1</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>1</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Wife</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education-num      Marital-status  Occupation   Relationship  Sex  \\\n",
       "0       5             13  Married-civ-spouse           0        Husband    0   \n",
       "1       2             10       Never-married           1      Own-child    0   \n",
       "2       0              6       Never-married           1      Unmarried    0   \n",
       "3       1             12  Married-civ-spouse           0        Husband    0   \n",
       "4       4              9       Never-married           0  Not-in-family    0   \n",
       "...    ..            ...                 ...         ...            ...  ...   \n",
       "48837   3             13       Never-married           0  Not-in-family    0   \n",
       "48838   4             14             Widowed           0  Not-in-family    1   \n",
       "48839   4              9  Married-civ-spouse           1        Husband    0   \n",
       "48840   2             10       Never-married           0      Unmarried    1   \n",
       "48841   1              9  Married-civ-spouse           0           Wife    1   \n",
       "\n",
       "       Capital-gain  Capital-loss  Hours-per-week  Income  \n",
       "0                 0             0              50       1  \n",
       "1                 0             0              40       0  \n",
       "2                 0             0              30       0  \n",
       "3                 0             0              40       1  \n",
       "4                 0             0              40       0  \n",
       "...             ...           ...             ...     ...  \n",
       "48837             0             0              40       0  \n",
       "48838             0             0              40       0  \n",
       "48839             0             0              40       1  \n",
       "48840             0             0              35       0  \n",
       "48841             0             0              40       0  \n",
       "\n",
       "[45222 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numerically encoding occupation: Occupaiton is grouped into white collar and blue collar \n",
    "occupation_mapping_dict = {\n",
    "    \"Tech-support\" : 0,\n",
    "    \"Craft-repair\" : 1, \n",
    "    \"Other-service\" : 1, #Wasn't sure about blue or white collar for other services \n",
    "    \"Sales\" : 0, \n",
    "    \"Exec-managerial\" : 0, \n",
    "    \"Prof-specialty\" : 0, \n",
    "    \"Handlers-cleaners\" : 1, \n",
    "    \"Machine-op-inspct\" : 1, \n",
    "    \"Adm-clerical\" : 0, \n",
    "    \"Farming-fishing\" : 1, \n",
    "    \"Transport-moving\" : 1, \n",
    "    \"Priv-house-serv\" : 1, \n",
    "    \"Protective-serv\" : 1, \n",
    "    \"Armed-Forces\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Occupation\"] = df[\"Occupation\"].map(occupation_mapping_dict)\n",
    "\n",
    "\n",
    "#Numerically encoding the sex variable \n",
    "sex_mapping_dict = {\n",
    "    \"Male\" : 0,\n",
    "    \"Female\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Sex\"] = df[\"Sex\"].map(sex_mapping_dict)\n",
    "\n",
    "\n",
    "#Encoding income variable\n",
    "income_mapping_dict = {\n",
    "    \"<=50K\" : 0,\n",
    "    \">50K\" : 1, \n",
    "    \"<=50K.\" : 0, \n",
    "    \">50K.\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Income\"] = df[\"Income\"].map(income_mapping_dict)\n",
    "\n",
    "\n",
    "# FOR MODELS\n",
    "# Group ages into discrete bins for models\n",
    "bins = [10,20,30,40,50,60,70,80,90]\n",
    "names = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "df['Age'] = pd.cut(df['Age'], bins, labels = names)\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will now employ one-hot encoding for :  Marital Status and Relationship ; no order in their values\n",
    "df = pd.get_dummies(df, columns = ['Relationship', 'Marital-status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y\n",
    "X = df.iloc[:, [0,1,2, 3, 4, 5, 6,8,9,10,11,12,13,14,15,16,17,18,19,20]]\n",
    "y = df.iloc[:, [7]]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "1980 fits failed out of a total of 3240.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.843335 using {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.843326 (0.006208) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.843317 (0.006202) with: {'C': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.843335 (0.006204) with: {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.843335 (0.006204) with: {'C': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.843335 (0.006208) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.843335 (0.006204) with: {'C': 1000, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.843317 (0.006202) with: {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.843317 (0.006202) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.843317 (0.006202) with: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.843335 (0.006208) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.843335 (0.006208) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.843326 (0.006202) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.843326 (0.006208) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.843326 (0.006208) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.843308 (0.006215) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.843308 (0.006215) with: {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.843317 (0.006218) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.843326 (0.006217) with: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.843317 (0.006218) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.843317 (0.006218) with: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.843317 (0.006218) with: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.843335 (0.006290) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.843317 (0.006297) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.843234 (0.006410) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.843243 (0.006374) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.843234 (0.006410) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.843243 (0.006423) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.843252 (0.006415) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.828639 (0.005249) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.826317 (0.004957) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.836231 (0.006565) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.837300 (0.006466) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.836241 (0.006568) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.836241 (0.006568) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.836231 (0.006565) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.828648 (0.005253) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.826317 (0.004957) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.836231 (0.006565) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.837300 (0.006466) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.836241 (0.006568) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.836231 (0.006565) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.836241 (0.006568) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary modules\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Defining our model \n",
    "model = LogisticRegression()\n",
    "\n",
    "#Initialising scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#For logistic regresion, need to scale our data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "#Need to transform our y data as\n",
    "y_train = y_train.ravel()\n",
    "Y_test = y_test.ravel()\n",
    "\n",
    "#Define all of our hyperparameters \n",
    "solvers = ['newton-cg', 'liblinear', 'lbfgs','newton-cholesky', 'sag', 'saga']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "c_values = [1000, 10, 1, 0.1, 0.001, 0.001]\n",
    "\n",
    "#Defining our search space \n",
    "space = dict(solver = solvers, penalty = penalty, C = c_values)\n",
    "\n",
    "#Defining our cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Initialising our grid search\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = space, n_jobs = -1,cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for scaled date:  0.8435746468750864\n",
      "Accuracy for unscaled data:  0.7791967272023661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    }
   ],
   "source": [
    "#Testing results for optimal hyperparameter combination, with scaled vs unscaled data \n",
    "\n",
    "model = LogisticRegression(solver = 'saga', penalty='l1', C = 0.1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_acc_scaled = model.score(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy for scaled date: ', train_acc_scaled)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "\n",
    "print('Accuracy for unscaled data: ', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36177, 20)\n",
      "Original accuracy:  0.8435746468750864\n",
      "Accuracy for data reduced to 15 dimensions:  0.8432982281560107\n",
      "Accuracy for data reduced to 10 dimensions:  0.8318821350581861\n",
      "Accuracy for data reduced to 5 dimensions:  0.83138458136385\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Want to use datasets of different dimensions \n",
    "\n",
    "model = LogisticRegression(solver = 'saga', penalty='l1', C = 0.1)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "original_acc = model.score(X_train_scaled, y_train)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "#From above, we get that dimension of X_train_scaled is 36177x20\n",
    "\n",
    "#Want to use PCA to reduce to 15, 10 and 5 and see if that has any effect \n",
    "pca = PCA(n_components=15)\n",
    "X_train_15 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_15, y_train)\n",
    "acc_15 = model.score(X_train_15, y_train)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_train_10 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_10, y_train)\n",
    "acc_10 = model.score(X_train_10, y_train)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "X_train_5 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_5, y_train)\n",
    "acc_5 = model.score(X_train_5, y_train)\n",
    "\n",
    "\n",
    "print('Original accuracy: ', original_acc)\n",
    "print('Accuracy for data reduced to 15 dimensions: ', acc_15)\n",
    "print('Accuracy for data reduced to 10 dimensions: ', acc_10)\n",
    "print('Accuracy for data reduced to 5 dimensions: ', acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, can see that the dimensionality reduction doesn't have much of an effect on overall accuracy\n",
    "#From results above, can see that errors are generated for many of the cases. This means that for that particular 'solver', convergence isn't acheived\n",
    "#Optimal set of hyperparameters is generated "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
