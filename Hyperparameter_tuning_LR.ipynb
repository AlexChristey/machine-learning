{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 Private\n",
      "1                 Private\n",
      "2                 Private\n",
      "4        Self-emp-not-inc\n",
      "6             Federal-gov\n",
      "               ...       \n",
      "48837             Private\n",
      "48838             Private\n",
      "48839             Private\n",
      "48840             Private\n",
      "48841             Private\n",
      "Name: 1, Length: 45222, dtype: object\n",
      "0                 Private\n",
      "1                 Private\n",
      "2                 Private\n",
      "4        Self-emp-not-inc\n",
      "6             Federal-gov\n",
      "               ...       \n",
      "48837             Private\n",
      "48838             Private\n",
      "48839             Private\n",
      "48840             Private\n",
      "48841             Private\n",
      "Name: Workclass, Length: 45222, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import hstack\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reading csv files\n",
    "df =  pd.read_csv('adult.data', sep=\",\", header=None, skipinitialspace=True)\n",
    "df2 = pd.read_csv('adult.test', sep=\",\", header=None, skipinitialspace=True)\n",
    "\n",
    "# Join the data and test files together\n",
    "df = pd.concat([df, df2])\n",
    "\n",
    "# Shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Replace all of ? with None\n",
    "df = df.replace(['?'], [None])\n",
    "# Drop all rows with None in them\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "#Making a duplicate to test of recursively selected features\n",
    "data = copy.deepcopy(df)\n",
    "# Check no None values remain\n",
    "df.isnull().sum()\n",
    "\n",
    "#Adding column headers to our data \n",
    "df.columns = [\"Age\", \"Workclass\", \"Fnlwgt\", \"Education\", \"Education-num\", \"Marital-status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\", \"Native-country\", \"Income\"]\n",
    "# Workclass, Fnlwgt, Race and Native-country are not worth using.\n",
    "# Education = Education num, so drop Education\n",
    "df = df.drop(columns=['Workclass', 'Race', 'Fnlwgt', 'Native-country', 'Education'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Wife</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>7298</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>1</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education-num      Marital-status  Occupation   Relationship  Sex  \\\n",
       "0       4              9  Married-civ-spouse           1           Wife    1   \n",
       "1       1             13       Never-married           0  Not-in-family    1   \n",
       "2       1             13       Never-married           0  Not-in-family    0   \n",
       "3       2             13            Divorced           0      Unmarried    1   \n",
       "5       2             13       Never-married           0  Not-in-family    0   \n",
       "...    ..            ...                 ...         ...            ...  ...   \n",
       "48837   2             11  Married-civ-spouse           0        Husband    0   \n",
       "48838   1             11  Married-civ-spouse           1        Husband    0   \n",
       "48839   3              9  Married-civ-spouse           1        Husband    0   \n",
       "48840   1              9       Never-married           1  Not-in-family    0   \n",
       "48841   1             13       Never-married           0      Own-child    1   \n",
       "\n",
       "       Capital-gain  Capital-loss  Hours-per-week  Income  \n",
       "0                 0             0              40       0  \n",
       "1                 0             0              40       0  \n",
       "2                 0             0              45       0  \n",
       "3                 0             0              50       0  \n",
       "5                 0             0              40       0  \n",
       "...             ...           ...             ...     ...  \n",
       "48837             0             0              40       0  \n",
       "48838             0             0              40       0  \n",
       "48839          7298             0              40       1  \n",
       "48840             0             0              40       0  \n",
       "48841             0             0              35       0  \n",
       "\n",
       "[45222 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numerically encoding occupation: Occupaiton is grouped into white collar and blue collar \n",
    "occupation_mapping_dict = {\n",
    "    \"Tech-support\" : 0,\n",
    "    \"Craft-repair\" : 1, \n",
    "    \"Other-service\" : 1, #Wasn't sure about blue or white collar for other services \n",
    "    \"Sales\" : 0, \n",
    "    \"Exec-managerial\" : 0, \n",
    "    \"Prof-specialty\" : 0, \n",
    "    \"Handlers-cleaners\" : 1, \n",
    "    \"Machine-op-inspct\" : 1, \n",
    "    \"Adm-clerical\" : 0, \n",
    "    \"Farming-fishing\" : 1, \n",
    "    \"Transport-moving\" : 1, \n",
    "    \"Priv-house-serv\" : 1, \n",
    "    \"Protective-serv\" : 1, \n",
    "    \"Armed-Forces\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Occupation\"] = df[\"Occupation\"].map(occupation_mapping_dict)\n",
    "\n",
    "\n",
    "#Numerically encoding the sex variable \n",
    "sex_mapping_dict = {\n",
    "    \"Male\" : 0,\n",
    "    \"Female\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Sex\"] = df[\"Sex\"].map(sex_mapping_dict)\n",
    "\n",
    "\n",
    "#Encoding income variable\n",
    "income_mapping_dict = {\n",
    "    \"<=50K\" : 0,\n",
    "    \">50K\" : 1, \n",
    "    \"<=50K.\" : 0, \n",
    "    \">50K.\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Income\"] = df[\"Income\"].map(income_mapping_dict)\n",
    "\n",
    "\n",
    "# FOR MODELS\n",
    "# Group ages into discrete bins for models\n",
    "bins = [10,20,30,40,50,60,70,80,90]\n",
    "names = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "df['Age'] = pd.cut(df['Age'], bins, labels = names)\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will now employ one-hot encoding for :  Marital Status and Relationship ; no order in their values\n",
    "df = pd.get_dummies(df, columns = ['Relationship', 'Marital-status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Income</th>\n",
       "      <th>Relationship_Husband</th>\n",
       "      <th>Relationship_Not-in-family</th>\n",
       "      <th>...</th>\n",
       "      <th>Relationship_Own-child</th>\n",
       "      <th>Relationship_Unmarried</th>\n",
       "      <th>Relationship_Wife</th>\n",
       "      <th>Marital-status_Divorced</th>\n",
       "      <th>Marital-status_Married-AF-spouse</th>\n",
       "      <th>Marital-status_Married-civ-spouse</th>\n",
       "      <th>Marital-status_Married-spouse-absent</th>\n",
       "      <th>Marital-status_Never-married</th>\n",
       "      <th>Marital-status_Separated</th>\n",
       "      <th>Marital-status_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825511</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education-num  Occupation  Sex  Capital-gain  Capital-loss  \\\n",
       "0       4              9           1    1     -0.146733      -0.21878   \n",
       "1       1             13           0    1     -0.146733      -0.21878   \n",
       "2       1             13           0    0     -0.146733      -0.21878   \n",
       "3       2             13           0    1     -0.146733      -0.21878   \n",
       "5       2             13           0    0     -0.146733      -0.21878   \n",
       "...    ..            ...         ...  ...           ...           ...   \n",
       "48837   2             11           0    0     -0.146733      -0.21878   \n",
       "48838   1             11           1    0     -0.146733      -0.21878   \n",
       "48839   3              9           1    0      0.825511      -0.21878   \n",
       "48840   1              9           1    0     -0.146733      -0.21878   \n",
       "48841   1             13           0    1     -0.146733      -0.21878   \n",
       "\n",
       "       Hours-per-week  Income  Relationship_Husband  \\\n",
       "0                  40       0                     0   \n",
       "1                  40       0                     0   \n",
       "2                  45       0                     0   \n",
       "3                  50       0                     0   \n",
       "5                  40       0                     0   \n",
       "...               ...     ...                   ...   \n",
       "48837              40       0                     1   \n",
       "48838              40       0                     1   \n",
       "48839              40       1                     1   \n",
       "48840              40       0                     0   \n",
       "48841              35       0                     0   \n",
       "\n",
       "       Relationship_Not-in-family  ...  Relationship_Own-child  \\\n",
       "0                               0  ...                       0   \n",
       "1                               1  ...                       0   \n",
       "2                               1  ...                       0   \n",
       "3                               0  ...                       0   \n",
       "5                               1  ...                       0   \n",
       "...                           ...  ...                     ...   \n",
       "48837                           0  ...                       0   \n",
       "48838                           0  ...                       0   \n",
       "48839                           0  ...                       0   \n",
       "48840                           1  ...                       0   \n",
       "48841                           0  ...                       1   \n",
       "\n",
       "       Relationship_Unmarried  Relationship_Wife  Marital-status_Divorced  \\\n",
       "0                           0                  1                        0   \n",
       "1                           0                  0                        0   \n",
       "2                           0                  0                        0   \n",
       "3                           1                  0                        1   \n",
       "5                           0                  0                        0   \n",
       "...                       ...                ...                      ...   \n",
       "48837                       0                  0                        0   \n",
       "48838                       0                  0                        0   \n",
       "48839                       0                  0                        0   \n",
       "48840                       0                  0                        0   \n",
       "48841                       0                  0                        0   \n",
       "\n",
       "       Marital-status_Married-AF-spouse  Marital-status_Married-civ-spouse  \\\n",
       "0                                     0                                  1   \n",
       "1                                     0                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "5                                     0                                  0   \n",
       "...                                 ...                                ...   \n",
       "48837                                 0                                  1   \n",
       "48838                                 0                                  1   \n",
       "48839                                 0                                  1   \n",
       "48840                                 0                                  0   \n",
       "48841                                 0                                  0   \n",
       "\n",
       "       Marital-status_Married-spouse-absent  Marital-status_Never-married  \\\n",
       "0                                         0                             0   \n",
       "1                                         0                             1   \n",
       "2                                         0                             1   \n",
       "3                                         0                             0   \n",
       "5                                         0                             1   \n",
       "...                                     ...                           ...   \n",
       "48837                                     0                             0   \n",
       "48838                                     0                             0   \n",
       "48839                                     0                             0   \n",
       "48840                                     0                             1   \n",
       "48841                                     0                             1   \n",
       "\n",
       "       Marital-status_Separated  Marital-status_Widowed  \n",
       "0                             0                       0  \n",
       "1                             0                       0  \n",
       "2                             0                       0  \n",
       "3                             0                       0  \n",
       "5                             0                       0  \n",
       "...                         ...                     ...  \n",
       "48837                         0                       0  \n",
       "48838                         0                       0  \n",
       "48839                         0                       0  \n",
       "48840                         0                       0  \n",
       "48841                         0                       0  \n",
       "\n",
       "[45222 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will now do feature scaling on Capital-gaine and Capital-loss\n",
    "col_names = ['Capital-gain', 'Capital-loss']\n",
    "features = df[col_names]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df[col_names] = scaler.fit_transform(features.values)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Age column data from string to numerical.\n",
    "df[[\"Age\"]] = df[[\"Age\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y\n",
    "X = df.iloc[:, [0,1,2, 3, 4, 5, 6,8,9,10,11,12,13,14,15,16,17,18,19,20]]\n",
    "y = df.iloc[:, [7]]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "1980 fits failed out of a total of 3240.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.842349 using {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842321 (0.003867) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842312 (0.003855) with: {'C': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842331 (0.003874) with: {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842340 (0.003880) with: {'C': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842331 (0.003874) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842331 (0.003874) with: {'C': 1000, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842312 (0.003855) with: {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842321 (0.003867) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842312 (0.003855) with: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842321 (0.003860) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842331 (0.003874) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842321 (0.003860) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842321 (0.003860) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842303 (0.003858) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842331 (0.003868) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842331 (0.003883) with: {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842321 (0.003874) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842312 (0.003868) with: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842321 (0.003874) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842321 (0.003874) with: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842321 (0.003874) with: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842294 (0.003831) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842303 (0.003896) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842238 (0.004036) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842349 (0.003985) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842248 (0.004040) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842248 (0.004036) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842248 (0.004036) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.827349 (0.003977) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.825220 (0.003577) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.835890 (0.005041) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.827358 (0.003979) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.825220 (0.003577) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.835890 (0.005041) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.834259 (0.004141) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary modules\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Defining our model \n",
    "model = LogisticRegression()\n",
    "\n",
    "#Initialising scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#For logistic regresion, need to scale our data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "#Need to transform our y data as\n",
    "y_train = y_train.ravel()\n",
    "Y_test = y_test.ravel()\n",
    "\n",
    "#Define all of our hyperparameters \n",
    "solvers = ['newton-cg', 'liblinear', 'lbfgs','newton-cholesky', 'sag', 'saga']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "c_values = [1000, 10, 1, 0.1, 0.001, 0.001]\n",
    "\n",
    "#Defining our search space \n",
    "space = dict(solver = solvers, penalty = penalty, C = c_values)\n",
    "\n",
    "#Defining our cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Initialising our grid search\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = space, n_jobs = -1,cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for scaled date:  0.8421925532797081\n",
      "Accuracy for unscaled data:  0.8429665256931199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Testing results for optimal hyperparameter combination, with scaled vs unscaled data \n",
    "\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# DO WE NEED THIS IF WE USE THE SCALING DONE ABOVE?!!!!!\n",
    "train_acc_scaled = model.score(X_train_scaled, y_train)\n",
    "print('Accuracy for scaled date: ', train_acc_scaled)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "\n",
    "print('Accuracy for unscaled data: ', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36177, 20)\n",
      "Original accuracy:  0.8421925532797081\n",
      "Accuracy for data reduced to 15 dimensions:  0.8426348232302292\n",
      "Accuracy for data reduced to 10 dimensions:  0.8294496503303204\n",
      "Accuracy for data reduced to 5 dimensions:  0.8288968128921691\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Want to use datasets of different dimensions \n",
    "\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "original_acc = model.score(X_train_scaled, y_train)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "#From above, we get that dimension of X_train_scaled is 36177x20\n",
    "\n",
    "#Want to use PCA to reduce to 15, 10 and 5 and see if that has any effect \n",
    "pca = PCA(n_components=15)\n",
    "X_train_15 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_15, y_train)\n",
    "acc_15 = model.score(X_train_15, y_train)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_train_10 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_10, y_train)\n",
    "acc_10 = model.score(X_train_10, y_train)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "X_train_5 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_5, y_train)\n",
    "acc_5 = model.score(X_train_5, y_train)\n",
    "\n",
    "\n",
    "print('Original accuracy: ', original_acc)\n",
    "print('Accuracy for data reduced to 15 dimensions: ', acc_15)\n",
    "print('Accuracy for data reduced to 10 dimensions: ', acc_10)\n",
    "print('Accuracy for data reduced to 5 dimensions: ', acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, can see that the dimensionality reduction doesn't have much of an effect on overall accuracy\n",
    "#From results above, can see that errors are generated for many of the cases. This means that for that particular 'solver', convergence isn't acheived\n",
    "#Optimal set of hyperparameters is generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age  Workclass  Fnlwgt  Education  Education-num      Marital-status  \\\n",
      "0       52        NaN  126978    HS-grad              9  Married-civ-spouse   \n",
      "1       24        NaN  184975  Bachelors             13       Never-married   \n",
      "2       26        NaN  122999  Bachelors             13       Never-married   \n",
      "3       34        NaN  304622  Bachelors             13            Divorced   \n",
      "5       39        NaN  352188  Bachelors             13       Never-married   \n",
      "...    ...        ...     ...        ...            ...                 ...   \n",
      "48837   39        NaN  314007  Assoc-voc             11  Married-civ-spouse   \n",
      "48838   30        NaN  231043  Assoc-voc             11  Married-civ-spouse   \n",
      "48839   50        NaN  268553    HS-grad              9  Married-civ-spouse   \n",
      "48840   27        NaN  181822    HS-grad              9       Never-married   \n",
      "48841   26        NaN  150226  Bachelors             13       Never-married   \n",
      "\n",
      "              Occupation   Relationship                Race     Sex  \\\n",
      "0      Machine-op-inspct           Wife  Asian-Pac-Islander  Female   \n",
      "1         Prof-specialty  Not-in-family               White  Female   \n",
      "2         Prof-specialty  Not-in-family               White    Male   \n",
      "3         Prof-specialty      Unmarried               White  Female   \n",
      "5           Adm-clerical  Not-in-family               White    Male   \n",
      "...                  ...            ...                 ...     ...   \n",
      "48837       Tech-support        Husband               White    Male   \n",
      "48838    Protective-serv        Husband               White    Male   \n",
      "48839   Transport-moving        Husband               White    Male   \n",
      "48840       Craft-repair  Not-in-family               White    Male   \n",
      "48841     Prof-specialty      Own-child               White  Female   \n",
      "\n",
      "       Capital-gain  Capital-loss  Hours-per-week Native-country  Income  \n",
      "0                 0             0              40          China   <=50K  \n",
      "1                 0             0              40  United-States  <=50K.  \n",
      "2                 0             0              45  United-States  <=50K.  \n",
      "3                 0             0              50  United-States   <=50K  \n",
      "5                 0             0              40  United-States  <=50K.  \n",
      "...             ...           ...             ...            ...     ...  \n",
      "48837             0             0              40  United-States   <=50K  \n",
      "48838             0             0              40  United-States   <=50K  \n",
      "48839          7298             0              40  United-States    >50K  \n",
      "48840             0             0              40  United-States  <=50K.  \n",
      "48841             0             0              35  United-States   <=50K  \n",
      "\n",
      "[45222 rows x 15 columns]\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "5       NaN\n",
      "         ..\n",
      "48837   NaN\n",
      "48838   NaN\n",
      "48839   NaN\n",
      "48840   NaN\n",
      "48841   NaN\n",
      "Name: Workclass, Length: 45222, dtype: float64\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "5       NaN\n",
      "         ..\n",
      "48837   NaN\n",
      "48838   NaN\n",
      "48839   NaN\n",
      "48840   NaN\n",
      "48841   NaN\n",
      "Name: Workclass, Length: 45222, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Want use SKLearn's built in recursive feature selection\n",
    "#Currently have copy of df as data, and need to peform numerical into categorical \n",
    "print(data)\n",
    "data.columns = [\"Age\", \"Workclass\", \"Fnlwgt\", \"Education\", \"Education-num\", \"Marital-status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\", \"Native-country\", \"Income\"]\n",
    "print(data[\"Workclass\"])\n",
    "#Age is already continuous\n",
    "\n",
    "#Numerically encoding workclass\n",
    "worklclass_mapping_dict = {\n",
    "    \"Private\" : 0,\n",
    "    \"Self-emp-not-inc\" : 1, \n",
    "    \"Self-emp-inc\" : 2, \n",
    "    \"Federal-gov\" : 3, \n",
    "    \"Local-gov\" : 4,\n",
    "    \"State-gov\" : 5, \n",
    "    \"Without-pay\" : 6, \n",
    "    \"Never-worked\" : 7\n",
    "}\n",
    "\n",
    "data[\"Workclass\"] = data[\"Workclass\"].map(worklclass_mapping_dict)\n",
    "print(data[\"Workclass\"])\n",
    "\n",
    "#Fnlwgt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "X, y = train_test_split(data)\n",
    "\n",
    "selector = RFE(model, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431047350526578\n",
      "AxesSubplot(0.125,0.125;0.62x0.755)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     27209\n",
      "           1       0.73      0.59      0.65      8968\n",
      "\n",
      "    accuracy                           0.84     36177\n",
      "   macro avg       0.80      0.76      0.77     36177\n",
      "weighted avg       0.84      0.84      0.84     36177\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD6CAYAAABqFRZtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAa00lEQVR4nO3dd5xV1dX/8c9iBhApBpQ6oIKgERsCDtj1hwVsQMSI8RHMQzKGgCWiUexRsTwWfIygjsGARikRETSUIGCnCDZERZrKAIIIAgoPMPeu3x9zmFxgKkxhH79vX/s15+5z9rn7mHHNyjr73mPujoiIhKFKZU9ARERKTkFbRCQgCtoiIgFR0BYRCYiCtohIQBS0RUQCoqAtIlIAM2tmZjPM7HMzW2Bm10b9d5nZCjP7KGrnpYwZaGaLzWyhmZ2b0t/OzOZH+x43M4v6q5vZ6Kh/tpkdWty80svhWneyfe1SLQSX3dRocmplT0H2QbnbVtjenqM0MafqQS2Ker9cYIC7f2BmtYF5ZjY12jfY3R9OPdjMWgM9gaOAJsDrZna4uyeAJ4EsYBYwEegMTAL6AOvdvaWZ9QQeBC4tas7KtEVECuDuq9z9g2h7E/A5kFHEkK7AKHff6u7LgMVAppk1Buq4+0zP+zTjc0C3lDEjou2XgE47svDCKGiLSLwkEyVvJRSVLY4HZkdd/c3sEzN71szqRn0ZwPKUYTlRX0a0vWv/TmPcPRfYABxY1FwUtEUkXhK5JW5mlmVmc1Na1q6nM7NawFjgOnffSF6p4zCgDbAKeGTHoQXMxovoL2pMocq9pi0iUpHck6U41rOB7ML2m1lV8gL2C+7+cjRmdcr+Z4DXopc5QLOU4U2BlVF/0wL6U8fkmFk6cACwrqg5K9MWkXhJJkveihDVlocBn7v7oyn9jVMO6w58Gm1PAHpGK0KaA62AOe6+CthkZh2jc/YCxqeM6R1t9wCmezHf4qdMW0TipRSZdjFOBq4A5pvZR1HfLcBlZtaGvDLGV8BVAO6+wMzGAJ+Rt/KkX7RyBKAvMByoQd6qkUlR/zDgeTNbTF6G3bO4SVl5fzWrlvxJQbTkTwpSFkv+tn39QYljTrVD2u71+1U0ZdoiEi9ll2nvkxS0RSRWPJFb2VMoVwraIhIvxdxgDJ2CtojEi8ojIiIBKcUnHUOkoC0i8aJMW0QkILoRKSISEN2IFBEJx38+hBhPCtoiEi+qaYuIBETlERGRgCjTFhEJSGJ7Zc+gXCloi0i8qDwiIhIQlUdERAKiTFtEJCAK2iIi4XDdiBQRCYhq2iIiAVF5REQkIMq0RUQCokxbRCQgyrRFRAKSq4cgiIiEQ5m2iEhAVNMWEQmIMm0RkYAo0xYRCYgybRGRgGj1iIhIQNwrewblSkFbROJFNW0RkYAoaIuIBEQ3IkVEApJIVPYMypWCtojEi8ojIiIBUdAWEQlIzGvaVSp7AiIiZcmTXuJWFDNrZmYzzOxzM1tgZtdG/fXMbKqZLYp+1k0ZM9DMFpvZQjM7N6W/nZnNj/Y9bmYW9Vc3s9FR/2wzO7S461PQFpF4SSZL3oqWCwxw9yOBjkA/M2sN3AxMc/dWwLToNdG+nsBRQGdgqJmlRed6EsgCWkWtc9TfB1jv7i2BwcCDxU1KQVtE4iWRKHkrgruvcvcPou1NwOdABtAVGBEdNgLoFm13BUa5+1Z3XwYsBjLNrDFQx91nursDz+0yZse5XgI67cjCC6OgLSLxUopM28yyzGxuSssq6JRR2eJ4YDbQ0N1XQV5gBxpEh2UAy1OG5UR9GdH2rv07jXH3XGADcGBRl6cbkaW0avV33HLPw6xdt54qZvTo2oUrft2NIcP+wdgJk6n7iwMAuPaq3px2UibvzfmAx576O9u351K1ajoD+vWhQ7s2AFx1/W189/06ErkJ2h53NLcN+CNpaWms/HY1t983mHU/bOCAOrV54I4badSgfiVetZTGM9mPcP55Z7Hmu7W0Ob4TAMce25qhTzxAzVr78/XXOVzRqz+bNv3IZZd1Z8D1ffPHHnvMkZzQoTMff7yAtscfw7Bhg6mx335MmjydP11/R2VdUlhKsXrE3bOB7KKOMbNawFjgOnffWEQiXNAOL6K/qDGFUqZdSulpadx49e959cVsXswezKiXX2PJsq8BuOLSbowdMYSxI4Zw2kmZANT9RR2eePAuxj3/JINuG8DAux/OP9cj9wzk5RFDeeUfT7H+hw1MmfE2AA8/8Tcu6tyJcc89Sd/f/obHnhpe4dcpe+6558Zw/gWX79T39FMPccut93F827N45ZVJ3DAgL1CPHDmO9iecQ/sTzuHK317DV18t5+OPFwAw5In76dv3Jn7Z+hRatWxO53PPrPBrCZJ7yVsxzKwqeQH7BXd/OepeHZU8iH6uifpzgGYpw5sCK6P+pgX07zTGzNKBA4B1Rc1JQbuU6h9Uj9ZHtASgZs39aXFIM1Z/932hxx95eEsa1M/7fzstmx/C1m3b2LZtGwC1atYEIDeRYHvudiz6o7tk2Td0aN8GgMy2xzHj7ZnldTlSDt5+Zzbr1v+wU98Rhx/GW2/PAuD1aW/Tvft5u43reWk3Ro8ZD0CjRg2oXac2s2bPA+D5F17ioos67zZGClBGNyKj2vIw4HN3fzRl1wSgd7TdGxif0t8zWhHSnLwbjnOiEsomM+sYnbPXLmN2nKsHMD2qexeq2KBtZr80s5uiZSr/G20fWdy4n4MVq1bz+aIlHHvUEQCMHPsq3Xv15bb7HmXDxk27HT/1jXc48vDDqFatWn5f1p9u5fQLLqPm/vtzzpmnAHBEqxZMfeNdAF5/8z1+2ryFHzZsrIArkvKyYMFCLrzwHAB6XHwBzZo22e2YS3pcyKjRrwCQ0aQRK3JW5e9bkbOKjCaNKmSuwUt6yVvRTgauAP6fmX0UtfOAB4CzzWwRcHb0GndfAIwBPgMmA/3cfcfdzr7A38i7ObkEmBT1DwMONLPFwPVEK1GKUmTQNrObgFHk1V3mAO9H2yPNrNiTx9nmzVv40633ctM1V1GrZk0u7X4+k8Y8y9jhQ6h/YD0eeuKZnY5fvPRrHh36LHfcePVO/dmDBzFj/Ats27ad2fM+BuCGfr9j7ofz6XFlP+Z+NJ+G9Q8kLS0NCdfvsq7nj3+4ktmzJlG7dk22bdu+0/7ME45n85YtLFiwEICC6qZedKlTdii71SPvuLu5+7Hu3iZqE939e3fv5O6top/rUsYMcvfD3P0Id5+U0j/X3Y+O9vXfkU27+/+5+yXu3tLdM919aXGXV9yNyD7AUe6+02+YmT0KLCD6C7Or6A5sFsDQR+7ld70uK24eQdmem8t1t97L+eecydlnnAzAQfXy19fT46Iu9LvxzvzX3675jmtvuYf7br+BgwvIsKpXr8aZp3RgxtuzOCmzLQ3qH8j/3n87kPfH4fU33qF2rZrlfFVSnhYuXEKX838DQKtWLTivS6ed9l/6666MHj0+/3XOilVkNG2c/zqjaWNWrlxdMZMNnMf8Y+zFlUeSwO5RBhpH+wrk7tnu3t7d28ctYLs7d9z/GC0OaUbvnr/K7/9u7X/uHUx78z1atjgEgI2bfuSPN97JdVddSdtjj8o/ZvPmLfljcnMTvDVzLs0PybtXsf6HDSSjX7xnnh9N9/PPKffrkvJVP7qvYWbcMvBans5+Pn+fmXHxxRfk17MBvv12DZs2/UiHzLYAXHF5D159dUrFTjpUZVce2ScVl2lfB0yLajc71h8eDLQE+pfjvPZZH36ygFcnT6PVYYdyce9+QN7yvomvv8nCRUvBIKNRQ+788zVAXp17ec5Knho+kqeGjwQg+7FBuDv9b7qLbdu3k0wk6dDuOH7d7XwA3v/wEx57ajhmRrtoKaCE4x/PD+H0007koIPq8dXSufzl7oepVasmffteCcArr0xk+IjR+cefdmpHVqxYxbJl3+x0nv79B+Yv+Zs8ZQaTJk+vyMsIV8y/e8SKuVGJmVUBMslbBG7kLVF5P6XAXqTta5eG+edMylWNJqdW9hRkH5S7bUWRnwYsiZ/uvrzEMafmHS/s9ftVtGI/XOPuSWBWBcxFRGTv5eohCCIi4Yh5eURBW0TiJdAbjCWloC0isRL3JX8K2iISL8q0RUQCoqAtIhKQYj6eHjoFbRGJleKe/Rg6BW0RiRcFbRGRgGj1iIhIQJRpi4gEREFbRCQcnlB5REQkHMq0RUTCoSV/IiIhUdAWEQlIvEvaCtoiEi+eG++oraAtIvES75itoC0i8aIbkSIiIVGmLSISDmXaIiIhUaYtIhIOz63sGZQvBW0RiRVXpi0iEhAFbRGRcCjTFhEJiIK2iEhAPGGVPYVypaAtIrGiTFtEJCCeVKYtIhIMZdoiIgFxV6YtIhKMuGfaVSp7AiIiZSmZsBK34pjZs2a2xsw+Tem7y8xWmNlHUTsvZd9AM1tsZgvN7NyU/nZmNj/a97iZWdRf3cxGR/2zzezQ4uakoC0iseJJK3ErgeFA5wL6B7t7m6hNBDCz1kBP4KhozFAzS4uOfxLIAlpFbcc5+wDr3b0lMBh4sLgJKWiLSKyUZdB297eAdSV8667AKHff6u7LgMVAppk1Buq4+0x3d+A5oFvKmBHR9ktApx1ZeGEUtEUkVtxL3swsy8zmprSsEr5NfzP7JCqf1I36MoDlKcfkRH0Z0fau/TuNcfdcYANwYFFvrKAtIrFSmkzb3bPdvX1Kyy7BWzwJHAa0AVYBj0T9BWXIXkR/UWMKpaAtIrHibiVue3Z+X+3uCXdPAs8AmdGuHKBZyqFNgZVRf9MC+ncaY2bpwAEUU45R0BaRWEkkrMRtT0Q16h26AztWlkwAekYrQpqTd8NxjruvAjaZWceoXt0LGJ8ypne03QOYHtW9C6V12iISK2X54RozGwmcARxkZjnAncAZZtaGvDLGV8BVee/rC8xsDPAZkAv0c/dEdKq+5K1EqQFMihrAMOB5M1tMXobds9g5FRPU99r2tUvj/ZRN2SM1mpxa2VOQfVDuthV7HXG/OPy8EsecX345MbiPTyrTFpFYKec8tNIpaItIrOhb/kREApJIxnt9hYK2iMSKyiMiIgFJ6qtZRUTCoe/TFhEJiMoje+mww7uW91tIgNoe1LKypyAxpfKIiEhAtHpERCQgMa+OKGiLSLyoPCIiEhCtHhERCUjMH8auoC0i8eIFPgwmPhS0RSRWclUeEREJhzJtEZGAqKYtIhIQZdoiIgFRpi0iEpCEMm0RkXDE/GljCtoiEi9JZdoiIuHQF0aJiARENyJFRAKSNJVHRESCkajsCZQzBW0RiRWtHhERCYhWj4iIBESrR0REAqLyiIhIQLTkT0QkIAll2iIi4VCmLSISEAVtEZGAxPwRkQraIhIvyrRFRAIS94+xV6nsCYiIlKWklbwVx8yeNbM1ZvZpSl89M5tqZouin3VT9g00s8VmttDMzk3pb2dm86N9j5vlfauVmVU3s9FR/2wzO7S4OSloi0isJEvRSmA40HmXvpuBae7eCpgWvcbMWgM9gaOiMUPNLC0a8ySQBbSK2o5z9gHWu3tLYDDwYHETUtAWkVgpy6Dt7m8B63bp7gqMiLZHAN1S+ke5+1Z3XwYsBjLNrDFQx91nursDz+0yZse5XgI67cjCC6OgLSKx4qVoe6ihu68CiH42iPozgOUpx+VEfRnR9q79O41x91xgA3BgUW+uoC0isVKamraZZZnZ3JSWtRdvXVCG7EX0FzWmUFo9IiKxUprVI+6eDWSX8i1Wm1ljd18VlT7WRP05QLOU45oCK6P+pgX0p47JMbN04AB2L8fsRJm2iMRKEi9x20MTgN7Rdm9gfEp/z2hFSHPybjjOiUoom8ysY1Sv7rXLmB3n6gFMj+rehVKmLSKxUpYfrjGzkcAZwEFmlgPcCTwAjDGzPsA3wCUA7r7AzMYAnwG5QD9335H49yVvJUoNYFLUAIYBz5vZYvIy7J7FzUlBW0RipSwfguDulxWyq1Mhxw8CBhXQPxc4uoD+/yMK+iWloC0isaKPsYuIBCTX4v3AMQVtEYmVeIdsBW0RiRmVR0REArIXS/mCoKAtIrES75CtoC0iMaPyiIhIQBIxz7UVtEUkVpRpi4gExJVpi4iEQ5m2FKp69Wr887XhVKtejfT0NCZOmMqjDwxlyLCHaNHyUADqHFCbjRs20eX0vK8X6HddHy79r1+RSCS4c+ADvDX9PQCqVk3nnv+5lY4ntyeZdB4a9DiTXn29si5N9tIrs0ex+cctJJMJErkJene5iqtv/wOnnn0S27flsuLrldz9pwf4ceOPALQ8sgUDH7yBmrX3J5l0rjzvKqyKcf/Tf6HpoU1IJpK8PfU9htxX2m8R/fnRkj8p1Nat2+jZrQ+bf9pCeno6YyeNYMbr79Cvz435x9x2zw1siv7DbHVECy78VRfOOqkbDRs14MVxz3D6CReQTCa5ekAWa79bxxmZF2Jm/KLuAZV1WVJG+l5yHRvWbch/PeetuQy97xkSiQT9b72KK6++nCcGPU1aWhp/+ett3HXNIBZ9toQD6tYhd3suVatX5YWnRjPvvQ9Jr5rO0DGDOfHMDsycMbsSr2rfF++Qre/T3mubf9oCQHrVdNLT09n1q3Av6HYu48dOBOCcLmfy6suT2LZtO8u/WcFXy76hTbtjAPj15d0Z8tjfAHB31q/7oeIuQirE7DfnkkjkfVPnp/M+o0Hj+gB0OL09iz9fwqLPlgCwYf1GkskkW7dsZd57HwKQuz2XL+Z/mT9GCpeLl7iFaI+Dtpn9tiwnEqoqVaow6c1/8uHCN3nnjVl8NG9+/r7ME9uxds33fLX0GwAaNm7IyhWr8/evWrmaRo0bUKdObQBuuKU//5oxmif//ggH1S/yMXGyr3P468iHGTE5m26XX7jb7gsvO4/3pudlzAe3aIY7PP7iQzw35Rmu+OPu3wZaq04tTj37JN5/Z165Tz10Xop/QrQ3mfZfCtuR+ty1H7cW+eSc4CWTSbqcfgkdjj6L49oezeFHtszf1/XiLox/eWL+64IesuzupKWn0SSjEXNnf8j5Z17KvPc/5ra7B1TI/KV8/K5rP3qd+3uuu/zPXHJlN47vcGz+vt9e818kchNMfnkqAGnpabTJPIbb+9/L77v154zOp3LCKW3zj09LS+PeoXcwethYVn6zqsKvJTRl+TT2fVGRQdvMPimkzQcaFjbO3bPdvb27t69VvV6ZT3pftHHjJma9+z5ndDoZyPsPrfMFZ/HquCn5x3y78luaZPznX1vjJg1Z/e13rF/3A5t/2szk16YB8K/xUzj6uCMr9gKkTK1d/T0A67//gTcmv03r4/P+9zz/knM55ayTuL3/PfnHrln1HR/M/IgN6zawdctW3p0+iyOOOTx//8CHbmD5shxG/e2lir2IQP3cM+2G5D3P7MIC2vflO7V9X70D6+aXNqrvV51TTu/Iki+XAXDKGR1ZsmgZ3678Tzlk6uQ3uPBXXahWrSrNDs6geYtD8sspr095kxNPOQGAk0/ryKKFSyv4aqSs7FdjP/avWSN/u8PpJ7Dki2V0PCOTK/r9hgFXDmTrlq35x896Yw4tWx9G9RrVSUtLo+2Jx7Hsy68A+MOf+1Crdk0eveOvlXEpQYp7pl3c6pHXgFru/tGuO8zsjfKYUEgaNKzPo0PvJS0tjSpVjNde+TfT/v0WABd178KEsRN3Ov7LL5bw2itTmDZzPLm5udz250Ekk3m/OvffNZjHnrqfO++7iXVr1zGg/+0Vfj1SNurVr8tDw+4F8kofU8a9zqw35jD23ReoVr0aT4x+BMi7GfnAzY+yacOPvPj0GEZMfBp3573ps3l32iwaNK7Pf1/Xi2WLvub5fz8DwD//Po7xL/6r0q4tBImin4sbPCvmwb977eB6x8T736DskUb7/TzKZlI6c1a+ufuNn1L6zSHdSxxzXvx63F6/X0XTOm0RiZVQa9UlpaAtIrESaq26pBS0RSRW9DF2EZGAqDwiIhKQuK8eUdAWkVhReUREJCC6ESkiEhDVtEVEAqLyiIhIQMr7U96VTUFbRGIloUxbRCQcKo+IiARE5RERkYAo0xYRCYiW/ImIBEQfYxcRCYjKIyIiAYl70C7uwb4iIkFx9xK34pjZV2Y238w+MrO5UV89M5tqZouin3VTjh9oZovNbKGZnZvS3y46z2Ize9zM9vgxZwraIhIrSbzErYTOdPc27t4+en0zMM3dWwHToteYWWugJ3AU0BkYamZp0ZgngSygVdQ67+n1KWiLSKx4Kf7ZQ12BEdH2CKBbSv8od9/q7suAxUCmmTUG6rj7TM9L759LGVNqCtoiEisJT5a4mVmWmc1NaVm7nM6Bf5vZvJR9Dd19FUD0s0HUnwEsTxmbE/VlRNu79u8R3YgUkVgpzSci3T0byC7ikJPdfaWZNQCmmtkXRRxbUJ3ai+jfI8q0RSRWyrKm7e4ro59rgHFAJrA6KnkQ/VwTHZ4DNEsZ3hRYGfU3LaB/jyhoi0islFVN28xqmlntHdvAOcCnwASgd3RYb2B8tD0B6Glm1c2sOXk3HOdEJZRNZtYxWjXSK2VMqak8IiKxkiy7T0Q2BMZFq/PSgRfdfbKZvQ+MMbM+wDfAJQDuvsDMxgCfAblAP3dPROfqCwwHagCTorZHFLRFJFbK6rtH3H0pcFwB/d8DnQoZMwgYVED/XODospiXgraIxErC4/1oXwVtEYmVMiyP7JMUtEUkVvTVrCIiAVGmLSISEGXaIiIBSeSvsosnBW0RiRU92FdEJCBxfwiCgraIxIoybRGRgGj1iIhIQLR6REQkIPoYu4hIQFTTFhEJiGraIiIBUaYtIhIQrdMWEQmIMm0RkYBo9YiISEB0I1JEJCAqj4iIBESfiBQRCYgybRGRgMS9pm1x/6u0LzGzLHfPrux5yL5FvxdSGlUqewI/M1mVPQHZJ+n3QkpMQVtEJCAK2iIiAVHQrliqW0pB9HshJaYbkSIiAVGmLSISEAXtCmJmnc1soZktNrObK3s+UvnM7FkzW2Nmn1b2XCQcCtoVwMzSgCFAF6A1cJmZta7cWck+YDjQubInIWFR0K4YmcBid1/q7tuAUUDXSp6TVDJ3fwtYV9nzkLAoaFeMDGB5yuucqE9EpFQUtCuGFdCnZTsiUmoK2hUjB2iW8ropsLKS5iIiAVPQrhjvA63MrLmZVQN6AhMqeU4iEiAF7Qrg7rlAf2AK8Dkwxt0XVO6spLKZ2UhgJnCEmeWYWZ/KnpPs+/SJSBGRgCjTFhEJiIK2iEhAFLRFRAKioC0iEhAFbRGRgChoi4gEREFbRCQgCtoiIgH5/1Yvzh4N0F8OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Getting final evaluation metrics for Logistic Regression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "#Fitting the optimal version of our model\n",
    "model.fit(X_train_scaled, y_train.ravel())\n",
    "\n",
    "#Getting predictions\n",
    "train_data_predictions = cross_val_predict(model, X_train, y_train.ravel(), cv=20)\n",
    "\n",
    "print(accuracy_score(y_train, train_data_predictions))\n",
    "\n",
    "#Getting confusion matrix \n",
    "confusion_matrix(y_train, train_data_predictions)\n",
    "classes_names = ['class 1','class 2','class 3', 'class 4']\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, train_data_predictions))\n",
    "print(sns.heatmap(cm, annot=True, fmt='d'))\n",
    "print(classification_report(y_train, train_data_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
