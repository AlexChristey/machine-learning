{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import hstack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reading csv files\n",
    "df =  pd.read_csv('adult.data', sep=\",\", header=None, skipinitialspace=True)\n",
    "df2 = pd.read_csv('adult.test', sep=\",\", header=None, skipinitialspace=True)\n",
    "\n",
    "# Join the data and test files together\n",
    "df = pd.concat([df, df2])\n",
    "\n",
    "# Shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Replace all of ? with None\n",
    "df = df.replace(['?'], [None])\n",
    "# Drop all rows with None in them\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# Check no None values remain\n",
    "df.isnull().sum()\n",
    "\n",
    "#Adding column headers to our data \n",
    "df.columns = [\"Age\", \"Workclass\", \"Fnlwgt\", \"Education\", \"Education-num\", \"Marital-status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\", \"Native-country\", \"Income\"]\n",
    "# Workclass, Fnlwgt, Race and Native-country are not worth using.\n",
    "# Education = Education num, so drop Education\n",
    "df = df.drop(columns=['Workclass', 'Race', 'Fnlwgt', 'Native-country', 'Education'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>0</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>1</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Wife</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Wife</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>0</td>\n",
       "      <td>Husband</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education-num      Marital-status  Occupation   Relationship  Sex  \\\n",
       "0       4              7  Married-civ-spouse           1        Husband    0   \n",
       "1       3             10  Married-civ-spouse           0        Husband    0   \n",
       "2       3              9            Divorced           1  Not-in-family    0   \n",
       "3       2             14  Married-civ-spouse           0        Husband    0   \n",
       "4       1             10       Never-married           0  Not-in-family    1   \n",
       "...    ..            ...                 ...         ...            ...  ...   \n",
       "48837   1              9       Never-married           1      Own-child    1   \n",
       "48838   4              6  Married-civ-spouse           0           Wife    1   \n",
       "48839   2              9  Married-civ-spouse           1        Husband    0   \n",
       "48840   1             12  Married-civ-spouse           0           Wife    1   \n",
       "48841   3              9  Married-civ-spouse           0        Husband    0   \n",
       "\n",
       "       Capital-gain  Capital-loss  Hours-per-week  Income  \n",
       "0                 0             0              45       0  \n",
       "1                 0             0              40       1  \n",
       "2                 0             0              65       0  \n",
       "3                 0             0              50       1  \n",
       "4                 0             0              25       0  \n",
       "...             ...           ...             ...     ...  \n",
       "48837             0             0              40       0  \n",
       "48838             0             0              36       0  \n",
       "48839             0             0              40       1  \n",
       "48840             0             0              40       0  \n",
       "48841             0             0              65       1  \n",
       "\n",
       "[45222 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numerically encoding occupation: Occupaiton is grouped into white collar and blue collar \n",
    "occupation_mapping_dict = {\n",
    "    \"Tech-support\" : 0,\n",
    "    \"Craft-repair\" : 1, \n",
    "    \"Other-service\" : 1, #Wasn't sure about blue or white collar for other services \n",
    "    \"Sales\" : 0, \n",
    "    \"Exec-managerial\" : 0, \n",
    "    \"Prof-specialty\" : 0, \n",
    "    \"Handlers-cleaners\" : 1, \n",
    "    \"Machine-op-inspct\" : 1, \n",
    "    \"Adm-clerical\" : 0, \n",
    "    \"Farming-fishing\" : 1, \n",
    "    \"Transport-moving\" : 1, \n",
    "    \"Priv-house-serv\" : 1, \n",
    "    \"Protective-serv\" : 1, \n",
    "    \"Armed-Forces\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Occupation\"] = df[\"Occupation\"].map(occupation_mapping_dict)\n",
    "\n",
    "\n",
    "#Numerically encoding the sex variable \n",
    "sex_mapping_dict = {\n",
    "    \"Male\" : 0,\n",
    "    \"Female\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Sex\"] = df[\"Sex\"].map(sex_mapping_dict)\n",
    "\n",
    "\n",
    "#Encoding income variable\n",
    "income_mapping_dict = {\n",
    "    \"<=50K\" : 0,\n",
    "    \">50K\" : 1, \n",
    "    \"<=50K.\" : 0, \n",
    "    \">50K.\" : 1\n",
    "    }\n",
    "\n",
    "df[\"Income\"] = df[\"Income\"].map(income_mapping_dict)\n",
    "\n",
    "\n",
    "# FOR MODELS\n",
    "# Group ages into discrete bins for models\n",
    "bins = [10,20,30,40,50,60,70,80,90]\n",
    "names = ['0', '1', '2', '3', '4', '5', '6', '7']\n",
    "df['Age'] = pd.cut(df['Age'], bins, labels = names)\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will now employ one-hot encoding for :  Marital Status and Relationship ; no order in their values\n",
    "df = pd.get_dummies(df, columns = ['Relationship', 'Marital-status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y\n",
    "X = df.iloc[:, [0,1,2, 3, 4, 5, 6,8,9,10,11,12,13,14,15,16,17,18,19,20]]\n",
    "y = df.iloc[:, [7]]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "1980 fits failed out of a total of 3240.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.842432 using {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842312 (0.004756) with: {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842312 (0.004756) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842294 (0.004697) with: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842276 (0.004752) with: {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842312 (0.004748) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842303 (0.004751) with: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842312 (0.004748) with: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842312 (0.004748) with: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842322 (0.004744) with: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.842340 (0.004756) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.842312 (0.004777) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.842312 (0.004851) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.842432 (0.004755) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.842303 (0.004849) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.842294 (0.004845) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.842312 (0.004837) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.826234 (0.004193) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.824142 (0.004665) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.834720 (0.004586) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.835006 (0.004144) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.834729 (0.004591) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.834720 (0.004586) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.834720 (0.004586) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "0.826234 (0.004193) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'sag'}\n",
      "0.824142 (0.004665) with: {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.834720 (0.004586) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.835006 (0.004144) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.834729 (0.004591) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cholesky'}\n",
      "0.834720 (0.004586) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.834720 (0.004586) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cholesky'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'sag'}\n",
      "0.000000 (0.000000) with: {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary modules\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Defining our model \n",
    "model = LogisticRegression()\n",
    "\n",
    "#Initialising scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#For logistic regresion, need to scale our data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "#Need to transform our y data as\n",
    "y_train = y_train.ravel()\n",
    "Y_test = y_test.ravel()\n",
    "\n",
    "#Define all of our hyperparameters \n",
    "solvers = ['newton-cg', 'liblinear', 'lbfgs','newton-cholesky', 'sag', 'saga']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "c_values = [1000, 10, 1, 0.1, 0.001, 0.001]\n",
    "\n",
    "#Defining our search space \n",
    "space = dict(solver = solvers, penalty = penalty, C = c_values)\n",
    "\n",
    "#Defining our cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Initialising our grid search\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = space, n_jobs = -1,cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for scaled date:  0.8424136882549687\n",
      "Accuracy for unscaled data:  0.8424413301268762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    }
   ],
   "source": [
    "#Testing results for optimal hyperparameter combination, with scaled vs unscaled data \n",
    "\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_acc_scaled = model.score(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy for scaled date: ', train_acc_scaled)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "\n",
    "print('Accuracy for unscaled data: ', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36177, 20)\n",
      "Original accuracy:  0.8424136882549687\n",
      "Accuracy for data reduced to 15 dimensions:  0.8422478370235232\n",
      "Accuracy for data reduced to 10 dimensions:  0.8296984271774884\n",
      "Accuracy for data reduced to 5 dimensions:  0.8287033197888161\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Want to use datasets of different dimensions \n",
    "\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "original_acc = model.score(X_train_scaled, y_train)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "#From above, we get that dimension of X_train_scaled is 36177x20\n",
    "\n",
    "#Want to use PCA to reduce to 15, 10 and 5 and see if that has any effect \n",
    "pca = PCA(n_components=15)\n",
    "X_train_15 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_15, y_train)\n",
    "acc_15 = model.score(X_train_15, y_train)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_train_10 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_10, y_train)\n",
    "acc_10 = model.score(X_train_10, y_train)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "X_train_5 = pca.fit_transform(X_train_scaled)\n",
    "model.fit(X_train_5, y_train)\n",
    "acc_5 = model.score(X_train_5, y_train)\n",
    "\n",
    "\n",
    "print('Original accuracy: ', original_acc)\n",
    "print('Accuracy for data reduced to 15 dimensions: ', acc_15)\n",
    "print('Accuracy for data reduced to 10 dimensions: ', acc_10)\n",
    "print('Accuracy for data reduced to 5 dimensions: ', acc_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, can see that the dimensionality reduction doesn't have much of an effect on overall accuracy\n",
    "#From results above, can see that errors are generated for many of the cases. This means that for that particular 'solver', convergence isn't acheived\n",
    "#Optimal set of hyperparameters is generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:561: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8426901069740442\n",
      "AxesSubplot(0.125,0.125;0.62x0.755)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     27150\n",
      "           1       0.73      0.59      0.65      9027\n",
      "\n",
      "    accuracy                           0.84     36177\n",
      "   macro avg       0.80      0.76      0.77     36177\n",
      "weighted avg       0.84      0.84      0.84     36177\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD7CAYAAAChScXIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ10lEQVR4nO3de5yW877/8denGR1U1Oigk1bIISE51HJsOXWyFHLeDCI7RWEvhb1XVrV+sp0Wa9E21JK1KGdapCRE6IR2UWhENNJpKjqoZu7P/mOu5nfLHO6pmbn7Xt7PHt/H3Pfn+l7X/b2Yx6dvn+t7X5e5OyIiEoYa6R6AiIikTklbRCQgStoiIgFR0hYRCYiStohIQJS0RUQCoqQtIlICM2tlZm+Z2UIz+9TMBkXxO8wsz8zmRa1H0j63mlmumX1uZl2T4t2iWK6ZDU2KtzGzWVH8aTOrWe64tE5bROSXzKwZ0MzdPzKz+sCHQG/gAmCDu9+zQ/92wHjgOKA58AZwULT5C+AMYBkwB7jY3Rea2TPAC+4+wcz+B/hfdx9d1rgyK+sES7Nt9RL9rSC/UKf5SekeguyGCrbm2a4eoyI5Z49G+5f6ee6+HFgevf7RzBYBLco4XC9ggrtvAb4ys1yKEjhArrsvATCzCUCv6HinApdEfcYBdwBlJm2VR0QkXhKFqbcUmdlvgKOAWVFooJnNN7OxZtYwirUAvk3abVkUKy2+D7DO3Qt2iJdJSVtE4sUTKTcz62dmc5Navx0PZ2b1gOeBwe7+A0Uz4QOADhTNxO+tztOr8vKIiEi1SiRS7uruOUBOadvNbA+KEvaT7v5CtM+KpO2PAq9Eb/OAVkm7t4xilBJfAzQws8xotp3cv1SaaYtIrLgnUm5lMTMDxgCL3P2+pHizpG7nAJ9ErycCF5lZLTNrA7QFZlN04bFttFKkJnARMNGLVoG8BfSJ9s8GXi7v/DTTFpF4KSwov09qTgAuAxaY2bwodhtwsZl1ABz4GrgWwN0/jVaDLAQKgAHuXghgZgOBKUAGMNbdP42ONwSYYGYjgY8p+kuiTFW+5E+rR6QkWj0iJamM1SNbl36Ucs6p2brjLn9eddNMW0TipZyyR+iUtEUkXipwITJEStoiEivlXWAMnZK2iMSLZtoiIgEp3JbuEVQpJW0RiReVR0REAqLyiIhIQDTTFhEJiGbaIiLh8IQuRIqIhEMzbRGRgKimLSISkAo8kSZEStoiEi+aaYuIBEQ1bRGRgFTeQxB2S0raIhIvmmmLiIQjesJXbClpi0i8aKYtIhIQrR4REQmIZtoiIgHR6hERkYCoPCIiEhCVR0REAqKkLSISEJVHREQCoguRIiIBUXlERCQgKo+IiAREM20RkYAoaYuIBMQ93SOoUkraIhIvBVo9IiISDl2IFBEJiGraIiIBUU1bRCQgmmmLiAQk5km7RroHICJSmbywMOVWFjNrZWZvmdlCM/vUzAZF8Swzm2pmi6OfDaO4mdmDZpZrZvPNrGPSsbKj/ovNLDspfrSZLYj2edDMrLzzU9IWkXhJJFJvZSsAbnb3dkBnYICZtQOGAtPcvS0wLXoP0B1oG7V+wGgoSvLAMKATcBwwbHuij/pck7Rft/IGpaQtIvHiidRbWYdxX+7uH0WvfwQWAS2AXsC4qNs4oHf0uhfwhBeZCTQws2ZAV2Cqu+e7+1pgKtAt2raXu890dweeSDpWqVTTFpF4SVT+6hEz+w1wFDALaOruy6NN3wNNo9ctgG+TdlsWxcqKLyshXibNtEUkXipQHjGzfmY2N6n12/FwZlYPeB4Y7O4/JG+LZsjVusZQM+0KWr5iFbeNuIc1a9diGH16deeyC3rz0Jh/8vzEyTRssDcAg67N5uTjj2Pd+h+48fY/88lnX9C7+xncfvN1xceaNPVtHn3iaTBo0mgfRv3xDzRssDf3/O0xpr83i8w9MmnVohkjb7uJverXS9cpy054NOdeevY4nZWrVtPhqNMAOOKIdjz8t1HUrbcnS5cu47LLB/LjjxsAOPzwQxn90F3U36seiUSCzr/tyZYtW7jwwl4MHXI97s7y71Zw+RXXs2bN2nSe2u6vnAuMydw9B8gpbbuZ7UFRwn7S3V+IwivMrJm7L49KHCujeB7QKmn3llEsD+iyQ/ztKN6yhP5lMq/ihejbVi+J1Ur3VavzWbUmn3YHH8jGjZu4oO8NPHjnfzH5zXfZs05trrykz8/6b9r8E599kcviJUvJXbK0OGkXFBRyaq9LefnJR2jYYG/ufWgMtWvXYkDff+O9WR/S6egOZGZmcN/DYwC46bq+1X6uValO85PSPYQqddKJndiwYSN///sDxUn7g/dfZciQEbzz7kyuyL6QNm32Y9gdd5ORkcGc2ZO54spBzJ+/kKyshqxbtx4z49ulH3H4kV1Ys2Yto+68nU2bNjN8xH1pPruqU7A1r9zVE+XZdN81KeecPW96tNTPi1ZyjAPy3X1wUvxuYI27jzKzoUCWu99iZj2BgUAPii46Pujux0UXIj8Etq8m+Qg42t3zzWw2cANFZZdJwF/dfVJZY1Z5pIIaN8qi3cEHAlC37p7s37oVK1atKbX/nnVq0/HI9tSqWfNncY/+bP7pJ9ydDRs30aRRFgAndDqazMwMAI447BBWrFxdRWcjVeXdGbPIX7vuZ7GD2u7PO+/OBOCNae9yzjk9ADjzjFNYsGAR8+cvBCA/fy2Jon+6Y2bUrbsnAPXr1+e771ZU30mEKuGpt7KdAFwGnGpm86LWAxgFnGFmi4HTo/dQlHSXALnAo8B1AO6eD4wA5kRteBQj6vNYtM+XwGvlDarc8oiZHULRVdHtBfI8YKK7Lypv37jLW76CRYu/5IjDDubjBQsZ//y/mDh5Gocd0pY/DLyGvfeqX+q+e2Rm8l//MZBzLutPnTq1ad2yBf+ZVDrZ7sVXX6fbaadU5WlINVm48AvOPrsrEydOoc95Z9GqZXMA2rbdH3eY9MqTNGq8D8888zL33DuagoICBlx/K/M+msbGjZvIzf2K62+4Lc1nEYBKumGUu88ASpuJn1ZCfwcGlHKsscDYEuJzgfYVGVeZM20zGwJMoGjgs6NmwPjonwW/Wps2bebG20cy5IZrqVe3Lhee05PXnhnL848/RON9srj7b4+Wuf+2ggKefvFVnv3733jr5Sc56IA2PPaPZ37W55Fx48nIyOCsM39Xlaci1eTqfjfR/9psZs18jfr167J16zYAMjMzOOH4Y7kseyCndOlN717dOfV3J5KZmcm/97ucY47rSqvWHZm/YBFDh1yf5rMIQOXNtHdL5ZVH+gLHuvsod/9n1EZRtEC81CJr8hXZx54YX5nj3S1sKyhg8O0j6Xnm7zijywkANMpqSEZGBjVq1KDP2d35ZOEXZR7js8VfArBfy+aYGV1PO4l5CxYWb3/p1am8895s7hp2Cyl8SUoC8PnnX9K95yV06tydCU+/zJIlXwOwLG85786YxZo1a9m8+Sdem/wmRx3Vng5HHgbAkiVLAXjuuX/x285Hp2v4wfBEIuUWovKSdgJoXkK8WbStRO6e4+7HuPsxV19+8a6Mb7fj7vzxzr+wf+tWZF90bnF81er84tfTpr/Pgfu3LvM4TRs14suvvymue34w+2P2/81+AMyYOZexTz3LX+8aRp3atSv/JCQtGjfeBwAz47ZbB/FIzj8AeP316bRvfwh16tQmIyODk0/qzKJFi8n77nsOPbQtjaJrHaeffjKffZabtvEHo7Aw9Rag8mrag4FpUcF9++Lw/YADKbpK+qvz8fxP+dfkabQ94Decl11Uvhp0bTaT3pjO54uXgEGLfZsy7JYbivc587xsNmzcxLaCAt58931y7v8zB7RpTf8rLyV7wC1kZmbQfN8m/Pn2mwH4830Ps3XbNq4ZfDtQdDFy2C36Z3FI/vmPhzjl5N/SqFEWXy+Zy5+G30O9enXp3/8KAF56aRKPj3sagHXr1vOXB3KY+cEk3J3Jk99k0mvTABgx8n7eevMFtm3bxjff5HFV3xvTdUrhCLTskapyl/yZWQ2KyiHJFyLnuHtKf03FbcmfVI64L/mTnVMZS/423nFxyjmn7h3jg6s9lrt6xN0TwMxqGIuIyK6L+Uxb34gUkXjRMyJFRAKimbaISDi8IMxVIalS0haReNFMW0QkIKppi4gERDNtEZFwuJK2iEhAdCFSRCQgmmmLiARESVtEJBxV/QjFdFPSFpF40UxbRCQgStoiIuHwAn25RkQkHPHO2UraIhIv+nKNiEhIlLRFRAKi8oiISDhUHhERCYgXKGmLiIRD5RERkXDE/BkIStoiEjNK2iIi4dBMW0QkIF6Q7hFULSVtEYkVzbRFRAKipC0iEhK3dI+gSilpi0isaKYtIhIQT2imLSISjEShkraISDDiXh6pke4BiIhUJk9Yyq08ZjbWzFaa2SdJsTvMLM/M5kWtR9K2W80s18w+N7OuSfFuUSzXzIYmxduY2awo/rSZ1SxvTEraIhIr7qm3FDwOdCshfr+7d4jaJAAzawdcBBwW7fOwmWWYWQbwENAdaAdcHPUFuCs61oHAWqBveQNS0haRWKnMmba7vwPkp/jRvYAJ7r7F3b8CcoHjopbr7kvcfSswAehlZgacCjwX7T8O6F3ehyhpi0isJAot5bYLBprZ/Kh80jCKtQC+TeqzLIqVFt8HWOde/MX77fEyKWmLSKxUZKZtZv3MbG5S65fCR4wGDgA6AMuBe6vyfHak1SMiEitegW9EunsOkFOx4/uK7a/N7FHglehtHtAqqWvLKEYp8TVAAzPLjGbbyf1LpZm2iMSKJ1JvO8PMmiW9PQfYvrJkInCRmdUyszZAW2A2MAdoG60UqUnRxcqJ7u7AW0CfaP9s4OXyPl8zbRGJlUQl3nvEzMYDXYBGZrYMGAZ0MbMOgANfA9cCuPunZvYMsBAoAAa4e2F0nIHAFCADGOvun0YfMQSYYGYjgY+BMeWOyVNc97Kztq1eEu+nbMpOqdP8pHQPQXZDBVvzdjnjfn5I95RzzsGfvRbc1yc10xaRWNHX2EVEAqIbRomIBKQya9q7IyVtEYmViiz5C5GStojEShWvrUg7JW0RiRWVR0REApLQhUgRkXBopr2LDjioV1V/hASoY6MD0z0EiSldiBQRCYhm2iIiAYn54hElbRGJl8JEvG9eqqQtIrES84exK2mLSLw4qmmLiAQjEfOitpK2iMRKQjNtEZFwqDwiIhKQQiVtEZFwaPWIiEhAlLRFRAKimraISEBifmdWJW0RiRct+RMRCUhhugdQxZS0RSRWEqaZtohIMGL+LXYlbRGJFy35ExEJiFaPiIgERF9jFxEJiGbaIiIBUU1bRCQgWj0iIhIQlUdERAKi8oiISEAKNdMWEQmHZtoiIgFR0hYRCUjcV4/USPcAREQqU8JSb+Uxs7FmttLMPkmKZZnZVDNbHP1sGMXNzB40s1wzm29mHZP2yY76Lzaz7KT40Wa2INrnQbPyb1GopC0isZKoQEvB40C3HWJDgWnu3haYFr0H6A60jVo/YDQUJXlgGNAJOA4Ytj3RR32uSdpvx8/6BSVtEYmVwgq08rj7O0D+DuFewLjo9Tigd1L8CS8yE2hgZs2ArsBUd89397XAVKBbtG0vd5/p7g48kXSsUqmmLSKxUg1frmnq7suj198DTaPXLYBvk/oti2JlxZeVEC+TZtoiEisVKY+YWT8zm5vU+lXks6IZcrVe+9RMW0RipSIZ1N1zgJwKfsQKM2vm7sujEsfKKJ4HtErq1zKK5QFddoi/HcVbltC/TJppi0isJPCU206aCGxfAZINvJwUvzxaRdIZWB+VUaYAZ5pZw+gC5JnAlGjbD2bWOVo1cnnSsUqlmbaIxEplPo3dzMZTNEtuZGbLKFoFMgp4xsz6AkuBC6Luk4AeQC6wCbgSwN3zzWwEMCfqN9zdt1/cvI6iFSp1gNeiViYlbRGJlcr8RqS7X1zKptNK6OvAgFKOMxYYW0J8LtC+ImNS0haRWNGtWUVEArILteogKGmLSKzEO2UraYtIzOgufyIiASmM+VxbSVtEYkUzbRGRgOhCpIhIQOKdspW0RSRmVB4REQmILkSKiARENW0pVa1aNXn2lcepWasmmZkZTJo4lftGPcxzrz5O3Xp1AWjUKIt5H33CNZcNonefnvQfdBVmxoYNG7n95hEs+vSLUo8j4Xpp1gQ2bdhMIlFIYUEh2d2v5do/XMXJXU/EPUH+6nUMH3wnq1esAeDmETdw/Kmd+GnzFobfeCefL1hcfKy69fZkwtvjmD5lBvfc/kC6TikY8U7ZStq7ZMuWrVzUuy+bNm4mMzOT518bx1tvzKBPzyuK+/zPuPuYOuktAL79ZhkXnHUl69f/QJfTT2TUX4bR64xLSz3Ox3Pnp+nMpDL0P38w6/PXF7//5+gJPHJ30T2DLuh7HlffmM2oofdx/KmdaNWmJeedcCntO7ZjyJ03cdVZ/Yv3u/aWvsybpd+FVMV9pq37ae+iTRs3A5C5RyaZmZkU3eirSL36dTnhpE5MmfQmAB/O/l/Wr/8BgI/nzKdZs6YpHUfiYeOGTcWv69Spzfb/xSd3PZFJz00B4JOPFlJ/73rs0yQLgEMOP4isxg2ZOX3OL44nJavkB/vudpS0d1GNGjV4bfqzfPz5dGa8PZN5Hy4o3ta1x6m8985MNvy48Rf7XXjZObw1bUZKx5EAOfx1/D2Mm5xD70t/XxzuP+Rq/jX3WbqdezqP3D0GgCb7NmLFdyuL+6z8bhVN9m2MmTFo2HU8OHx0tQ8/ZF6BPyHa6aRtZleWsa34uWsbtuz4ION4SSQSdD/lfDq1P50jO7bnoEMPLN529nk9ePn5X97T/LcnHsuF/3Yud95xf0rHkfBc03sgl3e9hsGX3sL5V/TmqE5HADD6rsf4/THnM/mFNzj/qnPLPEafK3rz/puzWLl8VXUMOTYK8ZRbiHZlpv2n0ja4e467H+Pux9SrlbULHxGOH374kQ9mzKHLaScA0DCrAR06tufN19/5Wb9D2h3Efz/wJ66+9AbWrV1f7nEkTKu+Xw3A2jXreHvyu7Q76tCfbZ/84lRO7XEyACu/X03T5k2KtzVp3piV36/i8KMP4/wrz+GlWRMY9Mf+9OjTlQG3Vei5s79Kv+ryiJnNL6Ut4P8/Nv5XK2ufhuy1V30AatWuxUldOvPlF18B0PPsM5g2ZTpbtmwt7t+8xb7kPHE/g/vfyldfLk3pOBKe2nVqs2fdOsWvO51yLF9+9hWt2rQo7nNK1xP5OvcbAN59/T169OkKQPuO7djww0bWrMznjwNHcvaxF9C700U8MHw0k56bwkP/r6LPoP31Sbin3EJU3uqRpkBXYO0OcQPer5IRBaRJ08bc9/BIMjIyqFHDeOWl15kWzax/f253Hn5gzM/6D7rl32mY1YCRd/8nAIUFhZx12kVlHkfCk9W4IXePGQlARmYGU158g5lvz2bUo8NpfUArEgnn+7wVjBpyLwDvTZvJ8ad15oX3n+KnzVsYceOodA4/eGGm4tRZWasUzGwM8Hd3n1HCtqfc/ZLyPmC/rMPj/t9QdsK+tX8dZTOpmNnfTd/lh4Vd0vqclHPOU0tfDO7hZGXOtN29bxnbyk3YIiLVLdRVIanSl2tEJFYKlLRFRMKhmbaISEBCXcqXKiVtEYmVuN8CQklbRGIl7jeMUtIWkVgJ9evpqVLSFpFY0UxbRCQgqmmLiAREq0dERAKiddoiIgFRTVtEJCCFHu8CiZK2iMSKyiMiIgEJ9eEGqVLSFpFYiXfKVtIWkZjRhUgRkYDEPWnvytPYRUR2O4WeSLmVx8y+NrMFZjbPzOZGsSwzm2pmi6OfDaO4mdmDZpYbPQC9Y9JxsqP+i80se1fOT0lbRGLFK/AnRb9z9w7ufkz0figwzd3bAtOi9wDdgbZR6weMhqIkDwwDOgHHAcO2J/qdoaQtIrHi7im3ndQLGBe9Hgf0Too/4UVmAg3MrBnQFZjq7vnuvhaYCnTb2Q9X0haRWEngKTcz62dmc5Navx0O58DrZvZh0ram7r48ev090DR63QL4NmnfZVGstPhO0YVIEYmVisyg3T0HyCmjy4nunmdmTYCpZvbZDvu7mVXrlU/NtEUkVgpJpNzK4+550c+VwIsU1aRXRGUPop8ro+55QKuk3VtGsdLiO0VJW0RiJeGeciuLmdU1s/rbXwNnAp8AE4HtK0CygZej1xOBy6NVJJ2B9VEZZQpwppk1jC5AnhnFdorKIyISK5V475GmwItmBkW58il3n2xmc4BnzKwvsBS4IOo/CegB5AKbgCsB3D3fzEYAc6J+w909f2cHpaQtIrFSWfcecfclwJElxNcAp5UQd2BAKccaC4ytjHEpaYtIrOgufyIiAdFd/kREAqKHIIiIBETlERGRgLhm2iIi4Yj7rVmVtEUkVnbhRlBBUNIWkVjRTFtEJCCFCdW0RUSCodUjIiIBUU1bRCQgqmmLiAREM20RkYDoQqSISEBUHhERCYjKIyIiAdGtWUVEAqJ12iIiAdFMW0QkIAndmlVEJBy6ECkiEhAlbRGRgMQ7ZYPF/W+l3YmZ9XP3nHSPQ3Yv+r2QiqiR7gH8yvRL9wBkt6TfC0mZkraISECUtEVEAqKkXb1Ut5SS6PdCUqYLkSIiAdFMW0QkIEra1cTMupnZ52aWa2ZD0z0eST8zG2tmK83sk3SPRcKhpF0NzCwDeAjoDrQDLjazdukdlewGHge6pXsQEhYl7epxHJDr7kvcfSswAeiV5jFJmrn7O0B+uschYVHSrh4tgG+T3i+LYiIiFaKkLSISECXt6pEHtEp63zKKiYhUiJJ29ZgDtDWzNmZWE7gImJjmMYlIgJS0q4G7FwADgSnAIuAZd/80vaOSdDOz8cAHwMFmtszM+qZ7TLL70zciRUQCopm2iEhAlLRFRAKipC0iEhAlbRGRgChpi4gERElbRCQgStoiIgFR0hYRCcj/AQsBanNcgdM2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Getting final evaluation metrics for Logistic Regression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "model = LogisticRegression(solver = grid_result.best_params_['solver'], penalty = grid_result.best_params_['penalty'], C = grid_result.best_params_['C'])\n",
    "\n",
    "#Fitting the optimal version of our model\n",
    "model.fit(X_train_scaled, y_train.ravel())\n",
    "\n",
    "#Getting predictions\n",
    "train_data_predictions = cross_val_predict(model, X_train, y_train.ravel(), cv=20)\n",
    "\n",
    "print(accuracy_score(y_train, train_data_predictions))\n",
    "\n",
    "#Getting confusion matrix \n",
    "confusion_matrix(y_train, train_data_predictions)\n",
    "classes_names = ['class 1','class 2','class 3', 'class 4']\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, train_data_predictions))\n",
    "print(sns.heatmap(cm, annot=True, fmt='d'))\n",
    "print(classification_report(y_train, train_data_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
